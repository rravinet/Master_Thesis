{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Importing vol indices\n",
    "# #source https://www.cboe.com/tradable_products/vix/vix_historical_data/\n",
    "# vix = pd.read_csv('https://cdn.cboe.com/api/global/us_indices/daily_prices/VIX_History.csv')\n",
    "# amz_vix = pd.read_csv('https://cdn.cboe.com/api/global/us_indices/daily_prices/VXAZN_History.csv')\n",
    "# appl_vix = pd.read_csv('https://cdn.cboe.com/api/global/us_indices/daily_prices/VXAPL_History.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from polygon import RESTClient\n",
    "import datetime as dt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "client = RESTClient(api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = 'http://en.wikipedia.org/wiki'\n",
    "djia_ticker_list = wiki + '/Dow_Jones_Industrial_Average'\n",
    "sp500_tickers_list = wiki + '/List_of_S%26P_500_companies'\n",
    "tickersSP500 = pd.read_html(sp500_tickers_list)[0].Symbol.to_list()\n",
    "djia_tickers = pd.read_html(djia_ticker_list)[1].Symbol.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "    def __init__(self, client, tickers, start_date = '2004-01-01', end_date = '2024-04-02', timespan = 'minute', multiplier = 5, limit = 50000):\n",
    "        self.client = client\n",
    "        self.tickers = tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.timespan = timespan\n",
    "        self.multiplier = multiplier\n",
    "        self.limit = limit\n",
    "    \n",
    "    def fetch_data(self, ticker):\n",
    "            data= pd.DataFrame(self.client.list_aggs(ticker,timespan = self.timespan, multiplier = self.multiplier,from_ = self.start_date, to = self.end_date,limit=self.limit))\n",
    "            data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('US/Eastern').dt.tz_localize(None)\n",
    "            data = data.rename(columns = {'timestamp': 'Date'}).set_index('Date')\n",
    "            filtered_data = data.between_time('09:30', '16:05')\n",
    "            filtered_data = filtered_data.drop(columns = ['open', 'vwap', 'high', 'low', 'volume', 'transactions', 'otc'])\n",
    "            data = data.drop(columns = ['open', 'vwap', 'high', 'low', 'volume', 'transactions', 'otc'])\n",
    "            return data, filtered_data\n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "    def process_data(self,df):\n",
    "        df['Day'] = pd.to_datetime(df.index).normalize()\n",
    "        df['log_ret'] = np.log(df['close']).diff()\n",
    "        df['squared_log_ret'] = df['log_ret']**2\n",
    "        df['returns'] = df['close'].pct_change()\n",
    "        df['squared_ret'] = df['returns']**2\n",
    "        return df\n",
    "    \n",
    "    def calculate_realized_var(self,df):\n",
    "        realized_var = df.groupby('Day').agg({'squared_log_ret': 'sum'})\n",
    "        return realized_var.rename(columns ={'squared_log_ret': 'daily_realised_log_var'})\n",
    "\n",
    "    \n",
    "    def processing_pipeline(self):\n",
    "        results = {}\n",
    "        for ticker in self.tickers:\n",
    "            data, filtered_data = self.fetch_data(ticker)\n",
    "            processed_data = self.process_data(data)\n",
    "            processed_filtered_data = self.process_data(filtered_data)\n",
    "            \n",
    "            realized_var = self.calculate_realized_var(processed_data)\n",
    "            realized_var_filtered = self.calculate_realized_var(processed_filtered_data)\n",
    "            \n",
    "            combined_data = realized_var.join(realized_var_filtered, lsuffix='', rsuffix='_filtered')\n",
    "            \n",
    "            \n",
    "            combined_data.to_csv(f'{ticker}_realized_combined.csv')\n",
    "            processed_data.to_csv(f'{ticker}_data.csv')\n",
    "            processed_filtered_data.to_csv(f'{ticker}_filtered_data.csv')\n",
    "           \n",
    "            results[ticker] = combined_data\n",
    "            \n",
    "\n",
    "        return results\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data = DataPipeline(client=client, tickers= ['SPY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = update_data.processing_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders created and files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "# #Moving FILES\n",
    "# directory = '/Users/raphaelravinet/Code/BSE/Thesis'\n",
    "\n",
    "# # Target directory \n",
    "# directory2 = '/Users/raphaelravinet/Code/BSE/Thesis/data'\n",
    "\n",
    "# files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "# tickers = set(f.split('_')[0] for f in files)\n",
    "\n",
    "\n",
    "# for ticker in tickers:\n",
    "\n",
    "#     ticker_folder = os.path.join(directory2, ticker)\n",
    "    \n",
    "#     # Create folder if it doesn't exist\n",
    "#     if not os.path.exists(ticker_folder):\n",
    "#         os.makedirs(ticker_folder)\n",
    "    \n",
    "#     for file in files:\n",
    "#         if file.startswith(ticker):\n",
    "#             shutil.move(os.path.join(directory, file), os.path.join(ticker_folder, file))\n",
    "\n",
    "# print(\"Folders created and files moved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_returns(df):\n",
    "#     df['returns'] = df['close'].pct_change()\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def process_folder(base_dir):\n",
    "#     for root, dirs, files in os.walk(base_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith(\"_filtered_data.csv\") or file.endswith(\"_daily_data.csv\"):\n",
    "#                 file_path = os.path.join(root, file)\n",
    "#                 df = pd.read_csv(file_path)\n",
    "#                 df = calculate_returns(df)\n",
    "#                 df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# base_dir = \"/Users/raphaelravinet/Code/BSE/Thesis/data\"\n",
    "# process_folder(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
