{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Importing vol indices\n",
    "# #source https://www.cboe.com/tradable_products/vix/vix_historical_data/\n",
    "# vix = pd.read_csv('https://cdn.cboe.com/api/global/us_indices/daily_prices/VIX_History.csv')\n",
    "# amz_vix = pd.read_csv('https://cdn.cboe.com/api/global/us_indices/daily_prices/VXAZN_History.csv')\n",
    "# appl_vix = pd.read_csv('https://cdn.cboe.com/api/global/us_indices/daily_prices/VXAPL_History.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from polygon import RESTClient\n",
    "import datetime as dt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "client = RESTClient(api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = 'http://en.wikipedia.org/wiki'\n",
    "djia_ticker_list = wiki + '/Dow_Jones_Industrial_Average'\n",
    "sp500_tickers_list = wiki + '/List_of_S%26P_500_companies'\n",
    "tickersSP500 = pd.read_html(sp500_tickers_list)[0].Symbol.to_list()\n",
    "djia_tickers = pd.read_html(djia_ticker_list)[1].Symbol.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "    def __init__(self, client, tickers, start_date = '2003-09-09', end_date = '2024-03-28', timespan = 'minute', multiplier = 1, limit = 50000):\n",
    "        self.client = client\n",
    "        self.tickers = tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.timespan = timespan\n",
    "        self.multiplier = multiplier\n",
    "        self.limit = limit\n",
    "    \n",
    "    def fetch_data(self, ticker):\n",
    "            data= pd.DataFrame(self.client.list_aggs(ticker,timespan = self.timespan, multiplier = self.multiplier,from_ = self.start_date, to = self.end_date,limit=self.limit))\n",
    "            data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('US/Eastern').dt.tz_localize(None)\n",
    "            data = data.rename(columns = {'timestamp': 'Date'}).set_index('Date')\n",
    "            filtered_data = data.between_time('09:30', '16:05')\n",
    "            filtered_data = filtered_data.drop(columns = ['open', 'vwap', 'high', 'low', 'volume', 'transactions', 'otc'])\n",
    "            data = data.drop(columns = ['open', 'vwap', 'high', 'low', 'volume', 'transactions', 'otc'])\n",
    "            return data, filtered_data\n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "    def process_data(self,df):\n",
    "        df['Day'] = pd.to_datetime(df.index).normalize()\n",
    "        df['log_ret'] = np.log(df['close']).diff()\n",
    "        df['squared_log_ret'] = df['log_ret']**2\n",
    "        df['returns'] = df['close'].pct_change()\n",
    "        df['squared_ret'] = df['returns']**2\n",
    "        return df\n",
    "    \n",
    "    def calculate_realized_var(self,df):\n",
    "        realized_var = df.groupby('Day').agg({'squared_log_ret': 'sum'})\n",
    "        return realized_var.rename(columns ={'squared_log_ret': 'daily_realised_log_var'})\n",
    "\n",
    "    \n",
    "    def processing_pipeline(self):\n",
    "        results = {}\n",
    "        for ticker in self.tickers:\n",
    "            data, filtered_data = self.fetch_data(ticker)\n",
    "            processed_data = self.process_data(data)\n",
    "            processed_filtered_data = self.process_data(filtered_data)\n",
    "            \n",
    "            realized_var = self.calculate_realized_var(processed_data)\n",
    "            realized_var_filtered = self.calculate_realized_var(processed_filtered_data)\n",
    "            \n",
    "            combined_data = realized_var.join(realized_var_filtered, lsuffix='', rsuffix='_filtered')\n",
    "            \n",
    "            \n",
    "            combined_data.to_csv(f'{ticker}_realized_combined.csv')\n",
    "            processed_data.to_csv(f'{ticker}_data.csv')\n",
    "            processed_filtered_data.to_csv(f'{ticker}_filtered_data.csv')\n",
    "           \n",
    "            results[ticker] = combined_data\n",
    "            \n",
    "\n",
    "        return results\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data = DataPipeline(client=client, tickers= ['QQQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = update_data.processing_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>close</th>\n",
       "      <th>Day</th>\n",
       "      <th>log_ret</th>\n",
       "      <th>squared_log_ret</th>\n",
       "      <th>returns</th>\n",
       "      <th>squared_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-09-10 09:30:00</td>\n",
       "      <td>33.7500</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-09-10 09:35:00</td>\n",
       "      <td>33.8300</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>5.605366e-06</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>5.618656e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-09-10 09:40:00</td>\n",
       "      <td>33.7400</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>7.096393e-06</td>\n",
       "      <td>-0.002660</td>\n",
       "      <td>7.077519e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-09-10 09:45:00</td>\n",
       "      <td>33.7200</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>3.515826e-07</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>3.513742e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-09-10 09:50:00</td>\n",
       "      <td>33.8200</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>8.768767e-06</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>8.794778e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286049</th>\n",
       "      <td>2024-03-28 15:45:00</td>\n",
       "      <td>444.4895</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>2.115748e-07</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>2.114775e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286050</th>\n",
       "      <td>2024-03-28 15:50:00</td>\n",
       "      <td>444.4250</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>2.106005e-08</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>2.105700e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286051</th>\n",
       "      <td>2024-03-28 15:55:00</td>\n",
       "      <td>443.9700</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>-0.001024</td>\n",
       "      <td>1.049230e-06</td>\n",
       "      <td>-0.001024</td>\n",
       "      <td>1.048156e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286052</th>\n",
       "      <td>2024-03-28 16:00:00</td>\n",
       "      <td>443.9400</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>4.566302e-09</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>4.565993e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286053</th>\n",
       "      <td>2024-03-28 16:05:00</td>\n",
       "      <td>444.1600</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>2.454605e-07</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>2.455822e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286054 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date     close         Day   log_ret  squared_log_ret  \\\n",
       "0       2003-09-10 09:30:00   33.7500  2003-09-10       NaN              NaN   \n",
       "1       2003-09-10 09:35:00   33.8300  2003-09-10  0.002368     5.605366e-06   \n",
       "2       2003-09-10 09:40:00   33.7400  2003-09-10 -0.002664     7.096393e-06   \n",
       "3       2003-09-10 09:45:00   33.7200  2003-09-10 -0.000593     3.515826e-07   \n",
       "4       2003-09-10 09:50:00   33.8200  2003-09-10  0.002961     8.768767e-06   \n",
       "...                     ...       ...         ...       ...              ...   \n",
       "286049  2024-03-28 15:45:00  444.4895  2024-03-28 -0.000460     2.115748e-07   \n",
       "286050  2024-03-28 15:50:00  444.4250  2024-03-28 -0.000145     2.106005e-08   \n",
       "286051  2024-03-28 15:55:00  443.9700  2024-03-28 -0.001024     1.049230e-06   \n",
       "286052  2024-03-28 16:00:00  443.9400  2024-03-28 -0.000068     4.566302e-09   \n",
       "286053  2024-03-28 16:05:00  444.1600  2024-03-28  0.000495     2.454605e-07   \n",
       "\n",
       "         returns   squared_ret  \n",
       "0            NaN           NaN  \n",
       "1       0.002370  5.618656e-06  \n",
       "2      -0.002660  7.077519e-06  \n",
       "3      -0.000593  3.513742e-07  \n",
       "4       0.002966  8.794778e-06  \n",
       "...          ...           ...  \n",
       "286049 -0.000460  2.114775e-07  \n",
       "286050 -0.000145  2.105700e-08  \n",
       "286051 -0.001024  1.048156e-06  \n",
       "286052 -0.000068  4.565993e-09  \n",
       "286053  0.000496  2.455822e-07  \n",
       "\n",
       "[286054 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/raphaelravinet/Code/BSE/Thesis/QQQ_filtered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders created and files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "# #Moving FILES\n",
    "# directory = '/Users/raphaelravinet/Code/BSE/Thesis'\n",
    "\n",
    "# # Target directory \n",
    "# directory2 = '/Users/raphaelravinet/Code/BSE/Thesis/data'\n",
    "\n",
    "# files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "# tickers = set(f.split('_')[0] for f in files)\n",
    "\n",
    "\n",
    "# for ticker in tickers:\n",
    "\n",
    "#     ticker_folder = os.path.join(directory2, ticker)\n",
    "    \n",
    "#     # Create folder if it doesn't exist\n",
    "#     if not os.path.exists(ticker_folder):\n",
    "#         os.makedirs(ticker_folder)\n",
    "    \n",
    "#     for file in files:\n",
    "#         if file.startswith(ticker):\n",
    "#             shutil.move(os.path.join(directory, file), os.path.join(ticker_folder, file))\n",
    "\n",
    "# print(\"Folders created and files moved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_returns(df):\n",
    "#     df['returns'] = df['close'].pct_change()\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def process_folder(base_dir):\n",
    "#     for root, dirs, files in os.walk(base_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith(\"_filtered_data.csv\") or file.endswith(\"_daily_data.csv\"):\n",
    "#                 file_path = os.path.join(root, file)\n",
    "#                 df = pd.read_csv(file_path)\n",
    "#                 df = calculate_returns(df)\n",
    "#                 df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# base_dir = \"/Users/raphaelravinet/Code/BSE/Thesis/data\"\n",
    "# process_folder(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for SPY saved to SPY_daily_data.csv\n",
      "Processed data for QQQ saved to QQQ_daily_data.csv\n",
      "    close         Day   log_ret   returns\n",
      "0  101.96  2003-09-10       NaN       NaN\n",
      "1  102.26  2003-09-11  0.002938  0.002942\n",
      "2  102.45  2003-09-12  0.001856  0.001858\n",
      "3  102.09  2003-09-15 -0.003520 -0.003514\n",
      "4  103.58  2003-09-16  0.014489  0.014595\n",
      "   close         Day   log_ret   returns\n",
      "0  33.27  2003-09-10       NaN       NaN\n",
      "1  33.64  2003-09-11  0.011060  0.011121\n",
      "2  33.82  2003-09-12  0.005337  0.005351\n",
      "3  33.49  2003-09-15 -0.009805 -0.009758\n",
      "4  34.40  2003-09-16  0.026810  0.027172\n"
     ]
    }
   ],
   "source": [
    "# Replace this with your actual client fetching method\n",
    "def fetch_data(client, ticker, start_date, end_date, timespan, multiplier, limit):\n",
    "    data = pd.DataFrame(client.list_aggs(ticker, timespan=timespan, multiplier=multiplier, from_=start_date, to=end_date, limit=limit))\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('US/Eastern').dt.tz_localize(None)\n",
    "    data = data.rename(columns={'timestamp': 'Date'}).set_index('Date')\n",
    "    data = data.drop(columns=['open', 'vwap', 'high', 'low', 'volume', 'transactions', 'otc'])\n",
    "    return data\n",
    "\n",
    "def process_data(df):\n",
    "    df['Day'] = pd.to_datetime(df.index).normalize()\n",
    "    df['log_ret'] = np.log(df['close']).diff()\n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    return df\n",
    "\n",
    "# Assuming `client` is already instantiated and available\n",
    "tickers = ['SPY', 'QQQ']\n",
    "start_date = '2003-09-10'\n",
    "end_date = '2024-03-28'\n",
    "timespan = 'day'\n",
    "multiplier = 1\n",
    "limit = 50000\n",
    "\n",
    "for ticker in tickers:\n",
    "    data = fetch_data(client, ticker, start_date, end_date, timespan, multiplier, limit)\n",
    "    processed_data = process_data(data)\n",
    "    processed_data.to_csv(f'{ticker}_daily_data.csv', index=False)\n",
    "    print(f\"Processed data for {ticker} saved to {ticker}_daily_data.csv\")\n",
    "\n",
    "# Check the first few rows of the processed data\n",
    "spy_data = pd.read_csv('SPY_daily_data.csv')\n",
    "qqq_data = pd.read_csv('QQQ_daily_data.csv')\n",
    "\n",
    "print(spy_data.head())\n",
    "print(qqq_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
